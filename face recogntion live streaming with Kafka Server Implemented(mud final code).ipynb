{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45318e32-c092-4fbc-9934-d58124275844",
   "metadata": {
    "id": "45318e32-c092-4fbc-9934-d58124275844",
    "outputId": "e9862a07-4392-4b85-aa3a-3e20ae0b916f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf23712a-9afe-4786-979e-3a8cdb9abf82",
   "metadata": {
    "id": "bf23712a-9afe-4786-979e-3a8cdb9abf82",
    "outputId": "62899a80-fb3c-4479-e3df-099c6239f352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: kafka-python\n"
     ]
    }
   ],
   "source": [
    "pip show kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb980c6-5578-4422-9956-0c95ba156043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.26.4\n",
    "#   This command specifically asks `pip` to find a pre-built wheel for `numpy` version 1.26.4. If a compatible wheel exists on the official package index, it will download and install it, completely avoiding the need for a compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00231a57-e45c-4d75-8008-6e73d3cff607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.6.0)\n",
      "Collecting numpy<2.0.0,>=1.24.0 (from facenet-pytorch)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (2.32.5)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.8.3)\n",
      "Requirement already satisfied: filelock in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.15.0)\n",
      "Requirement already satisfied: sympy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.9.0)\n",
      "Requirement already satisfied: colorama in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from tqdm<5.0.0,>=4.0.0->facenet-pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633ca0d4-c605-4db2-9c32-b9b38c4aeefe",
   "metadata": {
    "id": "633ca0d4-c605-4db2-9c32-b9b38c4aeefe",
    "outputId": "9e9210e7-96d3-484d-ae79-fda799b266fe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: filelock in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d93a36c-56fd-45e9-b8aa-ec1a19677ec5",
   "metadata": {
    "id": "8d93a36c-56fd-45e9-b8aa-ec1a19677ec5",
    "outputId": "e76580ae-375b-4116-9713-3264caa0b410",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.2.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48494259-a2c2-47ea-8d83-c313015f0df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: confluent_kafka in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79de389-1b2c-4c94-b68f-a1ef5e43c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2025.9.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eaea3b9-7cef-4d37-b4e8-e29fb56e04c8",
   "metadata": {
    "id": "3eaea3b9-7cef-4d37-b4e8-e29fb56e04c8",
    "outputId": "ef0075a6-f1d6-4813-d715-2cde6c763940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "# --- Imports (ensure these are at the top of your cell) ---\n",
    "from collections import deque\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import json # (NEW) For creating JSON strings\n",
    "\n",
    "# --- (NEW) KAFKA INTEGRATION: Import the Kafka Producer ---\n",
    "# You'll need to run: pip install kafka-python\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773497f7-6892-435e-9d98-5757341d7796",
   "metadata": {
    "id": "773497f7-6892-435e-9d98-5757341d7796",
    "outputId": "f83f52e0-13e1-4e17-d617-98bc448a30e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n",
      "Models initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Model and Device Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running on device: {device}')\n",
    "\n",
    "# Initialize MTCNN for face detection\n",
    "mtcnn = MTCNN(image_size=160, margin=14, keep_all=True, device=device)\n",
    "\n",
    "# Initialize InceptionResnetV1 for face embedding extraction\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "print(\"Models initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0223b2-72a5-471f-8c30-93a64013cbdd",
   "metadata": {
    "id": "1b0223b2-72a5-471f-8c30-93a64013cbdd",
    "outputId": "ae734e67-c1af-4704-bcd8-cc0652b87aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database generation function is defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Function to Build the Initial Database\n",
    "def generate_known_embeddings(database_path):\n",
    "    \"\"\"\n",
    "    Processes a directory of images to create a database of known face embeddings.\n",
    "    This function will run only if a pre-saved embeddings file is not found.\n",
    "    \"\"\"\n",
    "    known_embeddings = {}\n",
    "    for person_name in os.listdir(database_path):\n",
    "        person_dir = os.path.join(database_path, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "        embeddings_list = []\n",
    "        for image_name in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "            if not os.path.isfile(image_path):\n",
    "                continue\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                face_tensors = mtcnn(img)\n",
    "                if face_tensors is not None:\n",
    "                    for face_tensor in face_tensors:\n",
    "                        embedding = resnet(face_tensor.unsqueeze(0).to(device))\n",
    "                        embeddings_list.append(embedding.detach().cpu())\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process image {image_path}: {e}\")\n",
    "        if embeddings_list:\n",
    "            known_embeddings[person_name] = torch.cat(embeddings_list).mean(0, keepdim=True)\n",
    "            print(f\"Generated initial embeddings for {person_name}\")\n",
    "    return known_embeddings\n",
    "\n",
    "print(\"Database generation function is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fc8066-8e7e-46af-a6a4-8f8a568c3df7",
   "metadata": {
    "id": "61fc8066-8e7e-46af-a6a4-8f8a568c3df7",
    "outputId": "0a8c3b27-5ed5-455c-ad3b-eb3935a9706e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing face database...\n",
      "Loading known faces from saved file.\n",
      "\n",
      "---------------------------------\n",
      "Known faces database is ready.\n",
      "The following people are in the database:\n",
      "['access group employee', 'theif']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load or Create the Face Database\n",
    "print(\"Initializing face database...\")\n",
    "\n",
    "# Define paths\n",
    "database_folder = 'face_database'\n",
    "embeddings_file = 'known_faces_embeddings.pt'\n",
    "\n",
    "# Create database folder if it doesn't exist\n",
    "os.makedirs(database_folder, exist_ok=True)\n",
    "\n",
    "# Logic to load existing database or create a new one\n",
    "if os.path.exists(embeddings_file):\n",
    "    print(\"Loading known faces from saved file.\")\n",
    "    known_faces_embeddings = torch.load(embeddings_file)\n",
    "else:\n",
    "    print(\"No saved database found. Generating new embeddings from folder...\")\n",
    "    known_faces_embeddings = generate_known_embeddings(database_folder)\n",
    "    # Save the newly generated embeddings for future runs\n",
    "    torch.save(known_faces_embeddings, embeddings_file)\n",
    "\n",
    "print(\"\\n---------------------------------\")\n",
    "print(\"Known faces database is ready.\")\n",
    "\n",
    "if known_faces_embeddings:\n",
    "    print(\"The following people are in the database:\")\n",
    "    print(list(known_faces_embeddings.keys()))\n",
    "else:\n",
    "    print(\"The database is empty. You can start with an empty 'face_database' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3dbd58-7c4e-46ff-b8b0-15de7977c0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unassigned faces will be saved to: 'face_database\\_unassigned_faces'\n",
      "Attempting to connect Confluent Kafka producer...\n",
      "SUCCESS: Confluent Kafka producer created.\n",
      "Attempting to open live stream: https://www.youtube.com/watch?v=qKB-hXcztfg\n",
      "\n",
      "SUCCESS: Live stream opened. Starting face recognition...\n",
      "\n",
      "--- Real-time JSON Event Log ---\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T06:59:55.031931+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T06:59:56.312555+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T06:59:57.407116+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T06:59:58.889551+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:00.163435+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:01.452172+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:02.574436+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:03.719665+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:05.032611+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:06.235062+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:07.453594+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:08.734116+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:09.887280+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:11.328634+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:12.515296+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:13.812431+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:14.879807+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-10-10T07:00:16.825902+00:00\", \"presence\": 1, \"personName\": \"access group employee\", \"cameraId\": \"LiveYouTubeCam\"}\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# --- CELL 5 (LIVE STREAM FINAL V2): With PERSISTENT, VISIBLE LABELS ---\n",
    "# =========================================================================================\n",
    "\n",
    "# --- Imports ---\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "import socket\n",
    "import os\n",
    "from confluent_kafka import Producer\n",
    "import yt_dlp\n",
    "\n",
    "# --- General Configuration ---\n",
    "DISTANCE_THRESHOLD = 0.75\n",
    "FRAME_SKIP = 5 # Process 1 in every 5 frames, but display boxes on all frames\n",
    "\n",
    "# --- PASTE THE LIVE STREAM URL HERE ---\n",
    "YOUTUBE_LIVE_URL = \"https://www.youtube.com/watch?v=qKB-hXcztfg\" # <--- REPLACE THIS URL\n",
    "\n",
    "# --- All captures will happen inside the main database folder ---\n",
    "DATABASE_FOLDER = 'face_database'\n",
    "UNASSIGNED_FOLDER = os.path.join(DATABASE_FOLDER, '_unassigned_faces')\n",
    "os.makedirs(UNASSIGNED_FOLDER, exist_ok=True)\n",
    "print(f\"Unassigned faces will be saved to: '{UNASSIGNED_FOLDER}'\")\n",
    "\n",
    "# --- System & Message Configuration ---\n",
    "KAFKA_TOPIC = 'presence_events'\n",
    "CAMERA_ID = \"LiveYouTubeCam\"\n",
    "\n",
    "# --- CONFLUENT CLOUD CREDENTIALS ---\n",
    "BOOTSTRAP_SERVERS = \"pkc-oxqxx9.us-east-1.aws.confluent.cloud:9092\" # Replace with your actual server\n",
    "API_KEY = \"MHIVSVMGMGGDQTUT\"\n",
    "API_SECRET = \"cfltEV69I/NI2uHNBb5aooJFyKwYTJH9EuWP8hv+dtJ+GLd6sbuYW/dzRyYmbiQg\"\n",
    "\n",
    "# --- Initialize Confluent Kafka Producer ---\n",
    "producer = None\n",
    "try:\n",
    "    print(\"Attempting to connect Confluent Kafka producer...\")\n",
    "    conf = { 'bootstrap.servers': BOOTSTRAP_SERVERS, 'security.protocol': 'SASL_SSL', 'sasl.mechanisms': 'PLAIN', 'sasl.username': API_KEY, 'sasl.password': API_SECRET, 'client.id': socket.gethostname() }\n",
    "    producer = Producer(conf)\n",
    "    print(\"SUCCESS: Confluent Kafka producer created.\")\n",
    "    def delivery_report(err, msg):\n",
    "        if err is not None: print(f\"--- KAFKA ERROR: Message delivery failed: {err} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"--- KAFKA WARNING: Could not create producer. Reason: {e} ---\")\n",
    "\n",
    "# --- Get Live Stream URL using yt-dlp ---\n",
    "cap = None\n",
    "try:\n",
    "    print(f\"Attempting to open live stream: {YOUTUBE_LIVE_URL}\")\n",
    "    ydl_opts = {'format': 'best[height<=720]', 'quiet': True}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(YOUTUBE_LIVE_URL, download=False)\n",
    "        stream_url = info['url']   \n",
    "    cap = cv2.VideoCapture(stream_url)\n",
    "    if not cap.isOpened(): print(\"Error: Could not open the extracted live stream URL with OpenCV.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: Failed to get live stream URL. Details: {e}\")\n",
    "\n",
    "# --- Main Processing Loop ---\n",
    "if cap and cap.isOpened():\n",
    "    print(f\"\\nSUCCESS: Live stream opened. Starting face recognition...\")\n",
    "    frame_count = 0\n",
    "    # (--- NEW ---) Create a list to store face data between processing frames\n",
    "    last_known_faces = []\n",
    "    print(\"\\n--- Real-time JSON Event Log ---\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"\\nStream ended or could not read frame. Exiting.\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        \n",
    "        # --- Processing Logic (only runs on frames divisible by FRAME_SKIP) ---\n",
    "        if frame_count % FRAME_SKIP == 0:\n",
    "            try:\n",
    "                # (--- NEW ---) Clear the list for this new set of detections\n",
    "                last_known_faces.clear()\n",
    "                \n",
    "                pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                boxes, _ = mtcnn.detect(pil_image)\n",
    "                face_tensors = mtcnn(pil_image)\n",
    "\n",
    "                if face_tensors is not None:\n",
    "                    for face_tensor, box in zip(face_tensors, boxes):\n",
    "                        unknown_embedding = resnet(face_tensor.to(device).unsqueeze(0)).detach().cpu()\n",
    "                        min_dist = float('inf')\n",
    "                        recognized_name = \"Unknown\"  \n",
    "                        \n",
    "                        for name, known_emb in known_faces_embeddings.items():\n",
    "                            distance = (known_emb - unknown_embedding).norm().item()\n",
    "                            if distance < min_dist:\n",
    "                                min_dist = distance\n",
    "                                if min_dist < DISTANCE_THRESHOLD:\n",
    "                                    recognized_name = name\n",
    "                        \n",
    "                        # (--- NEW ---) Store the results instead of drawing immediately\n",
    "                        last_known_faces.append((box, recognized_name))\n",
    "                        \n",
    "                        # The auto-capture and Kafka logic still runs here\n",
    "                        if recognized_name == \"Unknown\":\n",
    "                            timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "                            filename = f\"unknown_{timestamp_str}.jpg\"\n",
    "                            save_path = os.path.join(UNASSIGNED_FOLDER, filename)\n",
    "                            face_image_to_save = pil_image.crop(box)\n",
    "                            face_image_to_save.save(save_path)\n",
    "                            print(f\"  -> Saved unassigned face to: {save_path}\")\n",
    "\n",
    "                        event_message = { \"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": datetime.now(timezone.utc).isoformat(), \"presence\": 1 if recognized_name != \"Unknown\" else 0, \"personName\": recognized_name, \"cameraId\": CAMERA_ID }\n",
    "                        encoded_message = json.dumps(event_message).encode('utf-8')\n",
    "                        print(json.dumps(event_message))\n",
    "\n",
    "                        if producer is not None:\n",
    "                            producer.poll(0)\n",
    "                            producer.produce(KAFKA_TOPIC, value=encoded_message, callback=delivery_report)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during frame processing: {e}\")\n",
    "\n",
    "        # #######################################################################\n",
    "        # ### (--- NEW ---) Persistent Drawing Logic (runs on EVERY frame) ###\n",
    "        # #######################################################################\n",
    "        # Redraw the last known faces on the current frame\n",
    "        for box, name in last_known_faces:\n",
    "            x1, y1, x2, y2 = [int(b) for b in box]\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "\n",
    "            # Draw the main bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            # Draw the background for the text\n",
    "            cv2.rectangle(frame, (x1, y2 - 25), (x2, y2), color, cv2.FILLED)\n",
    "            # Draw the name\n",
    "            cv2.putText(frame, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255, 255, 255), 1)\n",
    "\n",
    "        # Show the final frame (with or without new drawings)\n",
    "        cv2.imshow('Live Stream Face Recognition', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if producer is not None:\n",
    "        print(\"\\nFlushing remaining messages to Kafka...\")\n",
    "        producer.flush()\n",
    "        print(\"Kafka producer connection closed.\")\n",
    "    for i in range(5): cv2.waitKey(1)\n",
    "    print(\"Live stream processing stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d202b3e9-e96a-4a51-9fde-e16608f2af37",
   "metadata": {
    "id": "d202b3e9-e96a-4a51-9fde-e16608f2af37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving updated face database to file...\n",
      "Database saved successfully to 'known_faces_embeddings.pt'.\n",
      "The following people are now in the database:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Final Save of the Database\n",
    "print(\"\\nSaving updated face database to file...\")\n",
    "torch.save(known_faces_embeddings, embeddings_file)\n",
    "print(f\"Database saved successfully to '{embeddings_file}'.\")\n",
    "print(\"The following people are now in the database:\")\n",
    "print(list(known_faces_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881832a-a2b7-4768-864a-04ab041e529b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (Face Rec Project)",
   "language": "python",
   "name": "py311_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
