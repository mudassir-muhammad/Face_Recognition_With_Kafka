{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81be93f2-2263-404f-92fb-158b72a98bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b46061-8942-401d-8f51-8e926a20832f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f61a74-35bd-4e52-94f8-0a2cf4f9bcfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: torch in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: filelock in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dfd1a0-59fa-4d7e-b429-bbdb6939b3a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.6.0)\n",
      "Collecting numpy<2.0.0,>=1.24.0 (from facenet-pytorch)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (2.32.5)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.8.3)\n",
      "Requirement already satisfied: filelock in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.15.0)\n",
      "Requirement already satisfied: sympy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.9.0)\n",
      "Requirement already satisfied: colorama in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from tqdm<5.0.0,>=4.0.0->facenet-pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f1c9165-af7e-49b7-a1d2-561204cde1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f5db06-bccb-423e-a1d0-cd4ea519cc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n",
      "Models initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Model and Device Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running on device: {device}')\n",
    "\n",
    "# Initialize MTCNN for face detection\n",
    "mtcnn = MTCNN(image_size=160, margin=14, keep_all=True, device=device)\n",
    "\n",
    "# Initialize InceptionResnetV1 for face embedding extraction\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "print(\"Models initialized successfully.\")\n",
    "#  we have used pretrained model vgg face2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256ef92b-e27e-4c1e-844f-4c7fe75c142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database generation function is defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Function to Build the Initial Database\n",
    "def generate_known_embeddings(database_path):\n",
    "    \"\"\"\n",
    "    Processes a directory of images to create a database of known face embeddings.\n",
    "    This function will run only if a pre-saved embeddings file is not found.\n",
    "    \"\"\"\n",
    "    known_embeddings = {}\n",
    "    for person_name in os.listdir(database_path):\n",
    "        person_dir = os.path.join(database_path, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "        embeddings_list = []\n",
    "        for image_name in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "            if not os.path.isfile(image_path):\n",
    "                continue\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                face_tensors = mtcnn(img)\n",
    "                if face_tensors is not None:\n",
    "                    for face_tensor in face_tensors:\n",
    "                        embedding = resnet(face_tensor.unsqueeze(0).to(device))\n",
    "                        embeddings_list.append(embedding.detach().cpu())\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process image {image_path}: {e}\")\n",
    "        if embeddings_list:\n",
    "            known_embeddings[person_name] = torch.cat(embeddings_list).mean(0, keepdim=True)\n",
    "            print(f\"Generated initial embeddings for {person_name}\")\n",
    "    return known_embeddings\n",
    "\n",
    "print(\"Database generation function is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65f06bb3-edc1-4adb-a8e9-c59f008ba3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing face database...\n",
      "No saved database found. Generating new embeddings from folder...\n",
      "Generated initial embeddings for noman\n",
      "Generated initial embeddings for talha\n",
      "\n",
      "---------------------------------\n",
      "Known faces database is ready.\n",
      "The following people are in the database:\n",
      "['noman', 'talha']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load or Create the Face Database\n",
    "print(\"Initializing face database...\")\n",
    "\n",
    "# Define paths\n",
    "database_folder = 'Face_database'\n",
    "embeddings_file = 'known_faces_embeddings.pt'\n",
    "\n",
    "# Create database folder if it doesn't exist\n",
    "os.makedirs(database_folder, exist_ok=True) \n",
    "\n",
    "# Logic to load existing database or create a new one\n",
    "if os.path.exists(embeddings_file):\n",
    "    print(\"Loading known faces from saved file.\")\n",
    "    known_faces_embeddings = torch.load(embeddings_file)\n",
    "else:\n",
    "     print(\"No saved database found. Generating new embeddings from folder...\")\n",
    "     known_faces_embeddings = generate_known_embeddings(database_folder)\n",
    "   #  Save the newly generated embeddings for future runs\n",
    "     torch.save(known_faces_embeddings, embeddings_file)\n",
    "\n",
    "print(\"\\n---------------------------------\")\n",
    "print(\"Known faces database is ready.\")\n",
    "\n",
    "if known_faces_embeddings:\n",
    "    print(\"The following people are in the database:\")\n",
    "    print(list(known_faces_embeddings.keys()))\n",
    "else:\n",
    "    print(\"The database is empty. You can start with an empty 'face_database' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "735caa43-f168-4f04-9d24-e7f94e3f43c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video file. Press 'q' in the video window to quit.\n",
      "Saved new face for 'person_1758712321'\n",
      "Video stream stopped.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Main CCTV Processing and Recognition Loop\n",
    "\n",
    "# --- Configuration ---\n",
    "DISTANCE_THRESHOLD = 0.8\n",
    "MIN_FACE_SIZE = 40 * 40 # pixels\n",
    "\n",
    "# --- IMPORTANT: Set the path to your video file ---\n",
    "video_file_path = 'recording 4.mkv' \n",
    "\n",
    "    \n",
    "# --- ADD THIS: Initialize the presence flag for the target person ---\n",
    "#talha_majeed_present = 0\n",
    "\n",
    "# --- Video Capture ---\n",
    "cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "# --- Add a frame skip counter ---\n",
    "frame_count = 0\n",
    "frames_to_skip = 2 # This will process every 3rd frame (1 frame processed, 2 skipped)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file: {video_file_path}\")\n",
    "else:\n",
    "    print(\"Processing video file. Press 'q' in the video window to quit.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of video file reached.\")\n",
    "            break\n",
    "\n",
    "        # --- Frame skipping logic ---\n",
    "        if frame_count % (frames_to_skip + 1) != 0:\n",
    "            frame_count += 1\n",
    "            continue\n",
    "        frame_count += 1\n",
    "        # --- End of frame skipping logic ---\n",
    "\n",
    "\n",
    "        try:\n",
    "            img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            boxes, _ = mtcnn.detect(img)\n",
    "            face_tensors = mtcnn(img)\n",
    "            \n",
    "            if face_tensors is not None:\n",
    "                for face_tensor, box in zip(face_tensors, boxes):\n",
    "                    unknown_embedding = resnet(face_tensor.to(device).unsqueeze(0)).detach().cpu()\n",
    "                    \n",
    "                    min_dist = float('inf')\n",
    "                    recognized_name = \"Unknown\"\n",
    "                    for name, known_emb in known_faces_embeddings.items():\n",
    "                        distance = (known_emb - unknown_embedding).norm().item()\n",
    "                        if distance < min_dist:\n",
    "                            min_dist = distance\n",
    "                            if min_dist < DISTANCE_THRESHOLD:\n",
    "                                recognized_name = name\n",
    "            # --- ADD THIS: Check if the recognized person is our target ---\n",
    "                    #            if recognized_name == \"Talha_Majeed\":\n",
    "                               #    talha_majeed_present = 1\n",
    "\n",
    "                    \n",
    "                    if recognized_name == \"Unknown\":\n",
    "                        x1, y1, x2, y2 = [int(b) for b in box]\n",
    "                        if (x2 - x1) * (y2 - y1) > MIN_FACE_SIZE:\n",
    "                            new_person_name = f\"person_{int(time.time())}\"\n",
    "                            new_person_folder = os.path.join(database_folder, new_person_name)\n",
    "                            os.makedirs(new_person_folder, exist_ok=True)\n",
    "                            face_crop = frame[y1:y2, x1:x2]\n",
    "                            image_path = os.path.join(new_person_folder, \"1.jpg\")\n",
    "                            cv2.imwrite(image_path, face_crop)\n",
    "                            print(f\"Saved new face for '{new_person_name}'\")\n",
    "                            known_faces_embeddings[new_person_name] = unknown_embedding\n",
    "                            recognized_name = new_person_name\n",
    "\n",
    "                    x1, y1, x2, y2 = [int(b) for b in box]\n",
    "                    color = (0, 255, 0) if recognized_name != \"Unknown\" else (0, 0, 255)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    display_text = f\"{recognized_name} ({min_dist:.2f})\"\n",
    "                    cv2.rectangle(frame, (x1, y2 - 25), (x2, y2), color, cv2.FILLED)\n",
    "                    cv2.putText(frame, display_text, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255, 255, 255), 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during frame processing: {e}\")\n",
    "\n",
    "        cv2.imshow('CCTV Face Recognition', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Video stream stopped.\")\n",
    "\n",
    "      # --- ADD THIS: Display the final presence signal ---\n",
    "   # print(\"\\n---------------------------------\")\n",
    "    # print(f\"Signal for Talha_Majeed's presence: {talha_majeed_present}\")\n",
    "   # print(\"---------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19afa1b5-3bdf-45dd-8743-1d52d11180e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving updated face database to file...\n",
      "Database saved successfully to 'known_faces_embeddings.pt'.\n",
      "The following people are now in the database:\n",
      "['person_1758708480', 'person_1758708494', 'person_1758708498', 'person_1758708503', 'person_1758708526', 'person_1758708584', 'person_1758708607']\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Final Save of the Database\n",
    "print(\"\\nSaving updated face database to file...\")\n",
    "torch.save(known_faces_embeddings, embeddings_file)\n",
    "print(f\"Database saved successfully to '{embeddings_file}'.\")\n",
    "print(\"The following people are now in the database:\")\n",
    "print(list(known_faces_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792be126-9df8-4d66-b346-775af030d898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Face Rec Project)",
   "language": "python",
   "name": "py311_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
