{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45318e32-c092-4fbc-9934-d58124275844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf23712a-9afe-4786-979e-3a8cdb9abf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kafka-python\n",
      "Version: 2.2.15\n",
      "Summary: Pure Python client for Apache Kafka\n",
      "Home-page: https://github.com/dpkp/kafka-python\n",
      "Author: \n",
      "Author-email: Dana Powers <dana.powers@gmail.com>\n",
      "License: \n",
      "Location: E:\\python projects\\face recognition system\\.venv_py311\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "633ca0d4-c605-4db2-9c32-b9b38c4aeefe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: filelock in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56b0e08e-b818-451c-8371-271cc61d860a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (1.26.4)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (2.32.5)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from facenet-pytorch) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.8.3)\n",
      "Requirement already satisfied: filelock in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.15.0)\n",
      "Requirement already satisfied: sympy in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.9.0)\n",
      "Requirement already satisfied: colorama in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from tqdm<5.0.0,>=4.0.0->facenet-pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d93a36c-56fd-45e9-b8aa-ec1a19677ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in e:\\python projects\\face recognition system\\.venv_py311\\lib\\site-packages (2.2.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3eaea3b9-7cef-4d37-b4e8-e29fb56e04c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "# --- Imports (ensure these are at the top of your cell) ---\n",
    "from collections import deque\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import json # (NEW) For creating JSON strings\n",
    "\n",
    "# --- (NEW) KAFKA INTEGRATION: Import the Kafka Producer ---\n",
    "# You'll need to run: pip install kafka-python\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "773497f7-6892-435e-9d98-5757341d7796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n",
      "Models initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Model and Device Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running on device: {device}')\n",
    "\n",
    "# Initialize MTCNN for face detection\n",
    "mtcnn = MTCNN(image_size=160, margin=14, keep_all=True, device=device)\n",
    "\n",
    "# Initialize InceptionResnetV1 for face embedding extraction\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "print(\"Models initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0223b2-72a5-471f-8c30-93a64013cbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database generation function is defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Function to Build the Initial Database\n",
    "def generate_known_embeddings(database_path):\n",
    "    \"\"\"\n",
    "    Processes a directory of images to create a database of known face embeddings.\n",
    "    This function will run only if a pre-saved embeddings file is not found.\n",
    "    \"\"\"\n",
    "    known_embeddings = {}\n",
    "    for person_name in os.listdir(database_path):\n",
    "        person_dir = os.path.join(database_path, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "        embeddings_list = []\n",
    "        for image_name in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "            if not os.path.isfile(image_path):\n",
    "                continue\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                face_tensors = mtcnn(img)\n",
    "                if face_tensors is not None:\n",
    "                    for face_tensor in face_tensors:\n",
    "                        embedding = resnet(face_tensor.unsqueeze(0).to(device))\n",
    "                        embeddings_list.append(embedding.detach().cpu())\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process image {image_path}: {e}\")\n",
    "        if embeddings_list:\n",
    "            known_embeddings[person_name] = torch.cat(embeddings_list).mean(0, keepdim=True)\n",
    "            print(f\"Generated initial embeddings for {person_name}\")\n",
    "    return known_embeddings\n",
    "\n",
    "print(\"Database generation function is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61fc8066-8e7e-46af-a6a4-8f8a568c3df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing face database...\n",
      "Loading known faces from saved file.\n",
      "\n",
      "---------------------------------\n",
      "Known faces database is ready.\n",
      "The following people are in the database:\n",
      "['noman', 'talha']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load or Create the Face Database\n",
    "print(\"Initializing face database...\")\n",
    "\n",
    "# Define paths\n",
    "database_folder = 'face_database'\n",
    "embeddings_file = 'known_faces_embeddings.pt'\n",
    "\n",
    "# Create database folder if it doesn't exist\n",
    "os.makedirs(database_folder, exist_ok=True) \n",
    "\n",
    "# Logic to load existing database or create a new one\n",
    "if os.path.exists(embeddings_file):\n",
    "    print(\"Loading known faces from saved file.\")\n",
    "    known_faces_embeddings = torch.load(embeddings_file)\n",
    "else:\n",
    "    print(\"No saved database found. Generating new embeddings from folder...\")\n",
    "    known_faces_embeddings = generate_known_embeddings(database_folder)\n",
    "    # Save the newly generated embeddings for future runs\n",
    "    torch.save(known_faces_embeddings, embeddings_file)\n",
    "\n",
    "print(\"\\n---------------------------------\")\n",
    "print(\"Known faces database is ready.\")\n",
    "\n",
    "if known_faces_embeddings:\n",
    "    print(\"The following people are in the database:\")\n",
    "    print(list(known_faces_embeddings.keys()))\n",
    "else:\n",
    "    print(\"The database is empty. You can start with an empty 'face_database' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7593078e-13db-47f4-b0b7-2d517cd8436e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to Confluent Cloud...\n",
      "SUCCESS: Kafka producer created and connected to Confluent Cloud.\n",
      "\n",
      "Starting video playback. Processing 1 in every 5 frames.\n",
      "\n",
      "--- Real-time JSON Event Log ---\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:06.160143+00:00\", \"presence\": 1, \"personName\": \"noman\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:06.754081+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:06.878904+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:07.035161+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:09.063431+00:00\", \"presence\": 1, \"personName\": \"noman\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:09.198987+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:09.333070+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:09.551820+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:09.692881+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:09.895545+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:10.021071+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:12.064402+00:00\", \"presence\": 1, \"personName\": \"noman\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:12.189438+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:12.314418+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:12.439613+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:12.673491+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:14.768504+00:00\", \"presence\": 1, \"personName\": \"noman\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:14.913955+00:00\", \"presence\": 1, \"personName\": \"talha\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:15.062388+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:15.200014+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:15.338560+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:15.471596+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "{\"event_type\": \"FACE_RECOGNIZED\", \"timestamp\": \"2025-09-25T12:47:15.612037+00:00\", \"presence\": 0, \"personName\": \"Unknown\", \"cameraId\": \"FrontCounterCam\"}\n",
      "\n",
      "Flushing remaining messages to Kafka...\n",
      "Kafka producer connection closed.\n",
      "Video playback stopped.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5\n",
    "\n",
    "# =============================================================================\n",
    "# --- FINAL VERSION: Playback with PROVEN Confluent Cloud Integration ---\n",
    "# =============================================================================\n",
    "\n",
    "# --- Imports (ensure these are at the top of your cell) ---\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json # this is for kafka response\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "# --- General Configuration ---\n",
    "DISTANCE_THRESHOLD = 0.75 # Threshold Level\n",
    "MIN_FACE_SIZE = 40 * 40 # Pixels Size\n",
    "DATABASE_FOLDER = 'face_database'  # Database Foler\n",
    "VIDEO_FILE_PATH = 'recording 4.mkv' # <--- YOUR VIDEO FILE\n",
    "FRAME_SKIP = 5 # it does this blank, blank, blank, blank, DRAWING, blank, blank, blank, blank, DRAWING\n",
    "\n",
    "# --- System & Message Configuration ---\n",
    "KAFKA_TOPIC = 'presence_events'\n",
    "# BAKERY_ID = \"MainStreetBakery\"\n",
    "CAMERA_ID = \"FrontCounterCam\"\n",
    "\n",
    "# --- CONFLUENT CLOUD CREDENTIALS ---\n",
    "# Paste the exact, proven-working credentials from your kafka_test.py\n",
    "BOOTSTRAP_SERVERS = \"pkc-w8nyg.me-central1.gcp.confluent.cloud:9092\" # <-- YOUR BOOTSTRAP SERVER\n",
    "API_KEY = \"ZZDIITJZC7HLTZZX\"           # <-- YOUR API KEY\n",
    "API_SECRET = \"cfltSL1dRIX15BSXZN31q4g2ellCXCAvxkT5rp+byUmjkh1bNc+xt1hhXvQJOcBQ\"     # <-- YOUR API SECRET\n",
    "\n",
    "# --- Initialize Kafka Producer using the EXACT logic from kafka_test.py ---\n",
    "producer = None # Start with a None producer\n",
    "try:\n",
    "    print(\"Attempting to connect to Confluent Cloud...\")\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=BOOTSTRAP_SERVERS,\n",
    "        security_protocol='SASL_SSL',\n",
    "        sasl_mechanism='PLAIN',\n",
    "        sasl_plain_username=API_KEY,\n",
    "        sasl_plain_password=API_SECRET,\n",
    "        # Adding a timeout can help in debugging, but is optional\n",
    "        request_timeout_ms=15000, # 15 seconds\n",
    "        value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    "    )\n",
    "    print(f\"SUCCESS: Kafka producer created and connected to Confluent Cloud.\")\n",
    "except Exception as e:\n",
    "    print(f\"--- KAFKA WARNING: Could not connect to Confluent Cloud. ---\")\n",
    "    print(f\"--- Reason: {e} ---\")\n",
    "    print(f\"--- The script will run, but no signals will be sent. ---\")\n",
    "\n",
    "\n",
    "# --- Video Capture from a File ---\n",
    "cap = cv2.VideoCapture(VIDEO_FILE_PATH) # Change this for LIVE FEED\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000 / fps) if fps > 0 else 1\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file: {VIDEO_FILE_PATH}\")\n",
    "else:\n",
    "    print(f\"\\nStarting video playback. Processing 1 in every {FRAME_SKIP} frames.\")\n",
    "    frame_count = 0 \n",
    "    \n",
    "    print(\"\\n--- Real-time JSON Event Log ---\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"\\nEnd of video file reached.\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1 \n",
    "        \n",
    "        if frame_count % FRAME_SKIP != 0:\n",
    "            cv2.imshow('CCTV Face Recognition', frame)\n",
    "            if cv2.waitKey(delay) & 0xFF == ord('q'): break\n",
    "            continue \n",
    "        \n",
    "        try:\n",
    "            img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            boxes, _ = mtcnn.detect(img)\n",
    "            face_tensors = mtcnn(img)\n",
    "            \n",
    "            if face_tensors is not None:\n",
    "                for face_tensor, box in zip(face_tensors, boxes):\n",
    "                    # --- Face Recognition Logic ---\n",
    "                    # ... (this part is unchanged) ...\n",
    "                    unknown_embedding = resnet(face_tensor.to(device).unsqueeze(0)).detach().cpu()\n",
    "                    min_dist = float('inf')\n",
    "                    recognized_name = \"Unknown\"\n",
    "                    for name, known_emb in known_faces_embeddings.items():\n",
    "                        distance = (known_emb - unknown_embedding).norm().item()\n",
    "                        if distance < min_dist:\n",
    "                            min_dist = distance\n",
    "                            if min_dist < DISTANCE_THRESHOLD:\n",
    "                                recognized_name = name\n",
    "                    \n",
    "                    # --- JSON LOGGING AND KAFKA SIGNALING ---\n",
    "                    event_message = {\n",
    "                      \"event_type\": \"FACE_RECOGNIZED\",\n",
    "                      \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "                      \"presence\": 1 if recognized_name != \"Unknown\" else 0,\n",
    "                      \"personName\": recognized_name,\n",
    "               #       \"bakeryId\": BAKERY_ID, #When we are deploying it on the client-side\n",
    "                      \"cameraId\": CAMERA_ID\n",
    "                    }\n",
    "                    \n",
    "                    print(json.dumps(event_message))\n",
    "                    \n",
    "                    if producer is not None:\n",
    "                        try:\n",
    "                            producer.send(KAFKA_TOPIC, value=event_message)\n",
    "                        except Exception as e:\n",
    "                            print(f\"KAFKA ERROR: Could not send message. {e}\")\n",
    "                    \n",
    "                    # --- Drawing Logic ---\n",
    "                    x1, y1, x2, y2 = [int(b) for b in box]\n",
    "                    color = (0, 255, 0) if recognized_name != \"Unknown\" else (0, 0, 255)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    display_text = f\"{recognized_name} ({min_dist:.2f})\"\n",
    "                    cv2.rectangle(frame, (x1, y2 - 25), (x2, y2), color, cv2.FILLED)\n",
    "                    cv2.putText(frame, display_text, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255, 255, 255), 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during frame processing: {e}\")\n",
    "\n",
    "        cv2.imshow('CCTV Face Recognition', frame)\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'): break\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if producer is not None:\n",
    "        print(\"\\nFlushing remaining messages to Kafka...\")\n",
    "        producer.flush() \n",
    "        producer.close()\n",
    "        print(\"Kafka producer connection closed.\")\n",
    "    for i in range(5): cv2.waitKey(1)\n",
    "    print(\"Video playback stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d202b3e9-e96a-4a51-9fde-e16608f2af37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving updated face database to file...\n",
      "Database saved successfully to 'known_faces_embeddings.pt'.\n",
      "The following people are now in the database:\n",
      "['noman', 'talha']\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Final Save of the Database\n",
    "print(\"\\nSaving updated face database to file...\")\n",
    "torch.save(known_faces_embeddings, embeddings_file)\n",
    "print(f\"Database saved successfully to '{embeddings_file}'.\")\n",
    "print(\"The following people are now in the database:\")\n",
    "print(list(known_faces_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046c65c-d399-4db7-bb98-e1110277d8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Face Rec Project)",
   "language": "python",
   "name": "py311_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
